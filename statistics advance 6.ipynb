{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37903ca9-3363-4848-942b-e063030f2059",
   "metadata": {},
   "source": [
    "# Question.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78929180-9149-4c88-a200-5d160e44dd81",
   "metadata": {},
   "source": [
    "## Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529d01c-cf55-4587-819f-ca4dab5d468c",
   "metadata": {},
   "source": [
    "### ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups. To ensure the validity of the results, several assumptions need to be met. These assumptions include:\n",
    "1. Independence: The observations within each group or treatment level should be independent of each other. This means that the values or measurements within one group should not be influenced by or dependent on the values of another group.\n",
    "2. Normality: The distribution of the dependent variable (the variable being measured) should be approximately normally distributed within each group. This assumption is particularly important when the sample sizes are small. Violations of this assumption can lead to inaccurate p-values and confidence intervals.\n",
    "3. Homogeneity of variances (homoscedasticity): The variances of the dependent variable should be equal across all groups. This assumption implies that the spread or variability of the data should be roughly the same for each group. Violations of this assumption can affect the accuracy of the F-test and lead to incorrect conclusions.\n",
    "4. Random sampling: The observations should be randomly selected from the population of interest. Random sampling helps to ensure that the sample is representative of the population and allows for generalization of the results.\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "1. Non-independence: If observations within groups are not independent, such as in a repeated measures design where the same individuals are measured multiple times, the assumption of independence is violated. In such cases, specialized analyses like repeated measures ANOVA or mixed-effects models should be used instead.\n",
    "2. Non-normality: If the distribution of the dependent variable within groups is significantly non-normal, ANOVA results may not be valid. Non-normality can be assessed using graphical methods (e.g., histograms, Q-Q plots) or statistical tests (e.g., Shapiro-Wilk test). Transformations or non-parametric alternatives may be considered in cases of severe non-normality.\n",
    "3. Heterogeneity of variances: If the assumption of equal variances across groups is violated, it can affect the F-test results and lead to incorrect conclusions. This can be assessed using statistical tests such as Levene's test or by inspecting graphical representations of the data (e.g., boxplots). In such cases, alternative analyses like Welch's ANOVA or non-parametric tests may be more appropriate.\n",
    "4. Non-random sampling: If the sample is not randomly selected, the generalizability of the results may be compromised. Biased sampling can introduce systematic errors and limit the extent to which the findings can be applied to the target population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bf4fd-6e3c-4945-8e83-5a716bd7adf8",
   "metadata": {},
   "source": [
    "# Question.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a23932-eba1-416b-b342-75c453828b0b",
   "metadata": {},
   "source": [
    "## What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4842d3a-7212-4bd2-8080-3228e72a0fd4",
   "metadata": {},
   "source": [
    "### The three types of ANOVA (Analysis of Variance) are:\n",
    "1. One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more independent groups on a single dependent variable. It is the most basic form of ANOVA and is appropriate when there is only one factor or independent variable of interest. For example, a One-Way ANOVA can be used to determine if there are significant differences in test scores among students from three different schools.\n",
    "2. Two-Way ANOVA: Two-Way ANOVA is used when comparing the means of two or more independent groups on a single dependent variable, considering the effects of two independent variables. It allows for the examination of main effects (individual effects of each independent variable) and interaction effects (combined effects of the independent variables). Two-Way ANOVA is suitable when there are two factors or independent variables of interest, and we want to explore their individual and combined effects on the dependent variable. For example, a Two-Way ANOVA can be used to analyze the effects of both gender and age group on the scores of a cognitive test.\n",
    "3. Repeated Measures ANOVA: Repeated Measures ANOVA (also known as within-subjects ANOVA or ANOVA for correlated samples) is used when comparing the means of three or more related or matched groups on a single dependent variable. In this type of ANOVA, the same subjects or participants are measured under different conditions or at different time points. Repeated Measures ANOVA is appropriate when the dependent variable is measured repeatedly on the same individuals, such as in pre-test and post-test designs or when participants undergo multiple experimental conditions. For example, a Repeated Measures ANOVA can be used to analyze the effects of three different training programs on the performance of individuals by measuring their performance before training, after training, and at a follow-up time point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12206789-9116-44fc-841d-5a29213df577",
   "metadata": {},
   "source": [
    "# Question.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd6d08-18e7-45fd-8d06-ab1b0f70aad2",
   "metadata": {},
   "source": [
    "## What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a3f04-ba26-481d-b762-b27c1383b3d1",
   "metadata": {},
   "source": [
    "### Partitioning of variance in ANOVA refers to the breakdown of the total variance in the data into different components, each representing a different source of variation. This breakdown allows for a comprehensive understanding of how much of the total variation can be attributed to different factors or sources in the analysis.\n",
    "The partitioning of variance in ANOVA consists of three main components:\n",
    "1. Between-Group Variance: This component of variance represents the differences in the means of the groups being compared. It measures the variability between the groups and indicates whether there are significant differences among the group means.\n",
    "2. Within-Group Variance: Also known as the error or residual variance, this component represents the variation within each group. It captures the variability that cannot be explained by the factors under investigation. It includes random variability, measurement error, and any other sources of variation that are not accounted for by the independent variables.\n",
    "3. Total Variance: The total variance represents the overall variability in the data, regardless of the groups or conditions being compared. It is the sum of the between-group variance and the within-group variance.\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "1. Identification of Significant Effects: By examining the relative magnitudes of the between-group and within-group variances, ANOVA helps determine if there are significant differences among the groups being compared. If the between-group variance is significantly larger than the within-group variance, it suggests that the independent variable(s) have a significant effect on the dependent variable.\n",
    "2. Assessment of Model Fit: The partitioning of variance helps evaluate how well the ANOVA model fits the data. If the model accounts for a large proportion of the total variance (i.e., high between-group variance and low within-group variance), it indicates a good fit and suggests that the model explains a substantial amount of the variability in the data.\n",
    "3. Interpretation of Results: Partitioning of variance allows for the interpretation of the relative contributions of different factors to the overall variability. It helps researchers understand the importance of each factor in explaining the differences among the groups or conditions being studied.\n",
    "4. Planning Follow-up Analyses: Understanding the partitioning of variance can guide researchers in planning post-hoc or follow-up analyses, such as pairwise comparisons or further exploration of interaction effects. By identifying the sources of variation, researchers can focus on specific group comparisons or delve deeper into the factors influencing the observed differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76998b5d-f909-42c6-9fef-276265c270cd",
   "metadata": {},
   "source": [
    "# Question.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c7d8a-8b35-447a-a6b6-1d5c94d3d5f6",
   "metadata": {},
   "source": [
    "##  How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991da5a-d41e-4ed9-af00-68a059f7292d",
   "metadata": {},
   "source": [
    "To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, you can utilize the functionality provided by the `scipy` library. Here's an example of how you can calculate these sums of squares:\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Define the data for each group\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [2, 4, 6, 8, 10]\n",
    "group3 = [3, 6, 9, 12, 15]\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "groups = np.repeat(['Group 1', 'Group 2', 'Group 3'], [len(group1), len(group2), len(group3)])\n",
    "f_statistic, p_value = f_oneway(group1, group2, group3)\n",
    "mean_data = np.mean(data)\n",
    "sst = np.sum((data - mean_data) ** 2)\n",
    "mean_group = np.array([np.mean(data[groups == group]) for group in np.unique(groups)])\n",
    "sse = np.sum((mean_group - mean_data) ** 2 * np.bincount(groups))\n",
    "ssr = sst - sse\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "```\n",
    "In this example, we have three groups (`group1`, `group2`, and `group3`) with their corresponding data. We concatenate the data into a single array and create an array of group labels (`groups`). Then, we perform the one-way ANOVA using `f_oneway` function from `scipy.stats`. Finally, we calculate the SST, SSE, and SSR using the provided formulas and print the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf8652-e530-485e-8ac7-b9ef2fa8ade9",
   "metadata": {},
   "source": [
    "# Question.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abef2-f59d-41a6-add9-269b5d9ad689",
   "metadata": {},
   "source": [
    "## In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8091f8a3-aa4f-4964-92a4-96a204b7e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A: 437.5000000000019\n",
      "Main Effect B: 437.50000000000153\n",
      "Interaction Effect: 7.362701782062772e-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6],\n",
    "    'B': [2, 4, 6, 8, 10, 12],\n",
    "    'Y': [5, 10, 15, 20, 25, 30]\n",
    "})\n",
    "model = ols('Y ~ A + B + A:B', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "main_effect_A = anova_table['sum_sq']['A']\n",
    "main_effect_B = anova_table['sum_sq']['B']\n",
    "interaction_effect = anova_table['sum_sq']['A:B']\n",
    "print(\"Main Effect A:\", main_effect_A)\n",
    "print(\"Main Effect B:\", main_effect_B)\n",
    "print(\"Interaction Effect:\", interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07b005-963b-4e71-bc04-a9ceeab7091d",
   "metadata": {},
   "source": [
    "# Question.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2a4a7-ad48-434a-b5c4-44477d4a3bdb",
   "metadata": {},
   "source": [
    "##  Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7136f-b21b-4b09-b366-c2fdeaa7f996",
   "metadata": {},
   "source": [
    "### In the given scenario, where a one-way ANOVA was conducted and an F-statistic of 5.23 and a p-value of 0.02 were obtained, we can make the following conclusions and interpretations:\n",
    "1. Conclusions:\n",
    "   - There is evidence of a statistically significant difference between the means of the groups being compared.\n",
    "   - The null hypothesis, which assumes that there are no differences among the group means, can be rejected.\n",
    "   - The alternative hypothesis, which suggests that at least one group mean is different from the others, is supported.\n",
    "\n",
    "2. Interpretations:\n",
    "   - The F-statistic of 5.23 indicates that there is variation between the groups' means that is greater than would be expected by chance.\n",
    "   - The p-value of 0.02 indicates that the probability of obtaining an F-statistic as extreme as 5.23, assuming the null hypothesis is true, is 0.02 (or 2%). Since the p-value is less than the significance level (commonly set at 0.05), we reject the null hypothesis in favor of the alternative hypothesis.\n",
    "   - This suggests that the differences observed in the sample means are unlikely to have occurred due to random chance alone. Instead, they are likely due to genuine differences among the groups being compared.\n",
    "   - It is important to note that the ANOVA itself does not tell us which specific group means are different from each other. Post-hoc tests or pairwise comparisons are typically conducted to determine which group(s) differ significantly from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e8b5d9-94cc-4c9c-8aa7-dd044e51ee82",
   "metadata": {},
   "source": [
    "# Question.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f962485-f768-45e5-8e4a-139882c7c093",
   "metadata": {},
   "source": [
    "##  In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903124a-3ef9-419e-a3c9-61243b84b252",
   "metadata": {},
   "source": [
    "### Handling missing data in a repeated measures ANOVA is an important consideration to ensure valid and reliable results. Here are some common approaches to handle missing data in this context:\n",
    "1. Complete Case Analysis (Listwise Deletion): This method involves excluding any participant with missing data on any of the variables involved in the repeated measures ANOVA. Only participants with complete data across all variables are included in the analysis. While this approach is straightforward, it can lead to reduced sample size and potentially biased results if the missingness is related to the outcome or the variables of interest.\n",
    "2. Pairwise Deletion: This method allows for the inclusion of participants with missing data on some variables, but each analysis is conducted only on the available data for each specific comparison. This approach maximizes the use of available data but can lead to different sample sizes for different comparisons, potentially affecting statistical power and making it challenging to interpret and compare results across analyses.\n",
    "3. Mean Imputation: In this method, missing values are replaced with the mean value of the available data for that variable. This approach preserves the sample size and may maintain the overall mean of the variable, but it can underestimate the variability in the data, bias the estimates, and artificially reduce the standard errors. Additionally, imputing with the mean assumes that the missing values are missing completely at random (MCAR), which may not be the case in practice.\n",
    "4. Multiple Imputation: Multiple imputation involves creating multiple plausible imputations for the missing values based on observed data and using these imputed datasets to conduct the repeated measures ANOVA. This approach accounts for the uncertainty associated with missing data and allows for the estimation of appropriate standard errors. Multiple imputation assumes that the missing values are missing at random (MAR) or missing not at random (MNAR) but can yield more robust and valid results compared to other methods. However, it requires appropriate imputation models and may be computationally intensive.\n",
    "The consequences of using different methods to handle missing data can vary:\n",
    "- Complete case analysis and pairwise deletion may result in biased estimates and reduced statistical power, especially if the missing data are not missing completely at random (MCAR).\n",
    "- Mean imputation can lead to underestimation of variability, biased estimates, and artificial reduction in standard errors, which can affect the accuracy of hypothesis tests and confidence intervals.\n",
    "- Multiple imputation, when implemented appropriately, can produce more valid and reliable results by accounting for the uncertainty associated with missing data. However, it requires careful consideration of the missing data mechanism and appropriate imputation models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a118cd-b26a-46e8-9933-be83d751b03c",
   "metadata": {},
   "source": [
    "# Questtion.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23295457-e8fe-48ba-bbc4-c2cc5bffb7fe",
   "metadata": {},
   "source": [
    "## What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96a7b3-998c-4f86-b493-b990e8e5379e",
   "metadata": {},
   "source": [
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are often used to examine pairwise group differences. Some common post-hoc tests include:\n",
    "1. Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is widely used and compares all possible pairwise group differences. It controls the family-wise error rate, making it suitable when conducting multiple comparisons. It is conservative and maintains an overall Type I error rate.\n",
    "2. Bonferroni Correction: The Bonferroni correction is a simple adjustment to the significance level for each individual comparison to maintain the overall family-wise error rate. It divides the desired significance level (e.g., 0.05) by the number of comparisons. Bonferroni correction is conservative and is appropriate when the number of comparisons is relatively small.\n",
    "3. Scheffé's Test: Scheffé's test is more conservative than Tukey's HSD but is appropriate when conducting a large number of pairwise comparisons. It controls the family-wise error rate and is more powerful in detecting significant differences between groups.\n",
    "4. Dunnett's Test: Dunnett's test compares each group mean to a control or reference group mean. It is used when there is a specific control group, and the interest lies in comparing other groups to this reference group.\n",
    "5. Games-Howell Test: The Games-Howell test is a non-parametric alternative used when the assumption of equal variances is violated. It performs pairwise comparisons between groups with unequal variances and adjusts for multiple comparisons.\n",
    "Example situation:\n",
    "Suppose a researcher conducts an experiment to compare the effectiveness of three different treatment methods for reducing anxiety levels. The ANOVA results indicate a significant overall effect, suggesting that at least one treatment method differs from the others. In this case, a post-hoc test would be necessary to determine which specific treatment methods differ significantly.\n",
    "The researcher decides to use Tukey's HSD test as the post-hoc test to compare all possible pairwise differences between the treatment groups. This test will allow them to identify which treatment methods are significantly different from each other in terms of their impact on anxiety levels.\n",
    "By conducting Tukey's HSD test, the researcher can obtain specific information about the significant pairwise differences, enabling a more comprehensive understanding of the treatment effects and informing subsequent analysis or decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86665e23-731c-4669-8849-3504e1d1b98b",
   "metadata": {},
   "source": [
    "# Question.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef9480-ed71-48e5-a0d9-83b859e8b857",
   "metadata": {},
   "source": [
    "## A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c19854d-53bf-422c-8de6-7260dc39359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 22.659441885667835\n",
      "p-value: 1.1982238136397129e-08\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "diet_A = [3, 4, 5, 4, 3, 6, 7, 2, 4, 5, 3, 4, 5, 4, 3, 6, 7, 2, 4, 5, 3, 4, 5, 4, 3, 6, 7, 2, 4, 5]\n",
    "diet_B = [2, 3, 4, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 2, 3, 4, 2, 3, 4, 5, 2, 3]\n",
    "diet_C = [1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2]\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6dcbf2-949b-42af-9cf9-a37cbe33910a",
   "metadata": {},
   "source": [
    "# Question.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc812ef-c3c7-44a9-a785-e4924fe5505e",
   "metadata": {},
   "source": [
    "##  A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd80a22-8c19-4a49-93db-d3cbd7d929c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      df        sum_sq       mean_sq             F    PR(>F)\n",
      "Software             2.0  1.626667e+02  8.133333e+01  1.626667e+02  0.000006\n",
      "Experience           1.0  1.200000e+01  1.200000e+01  2.400000e+01  0.002714\n",
      "Software:Experience  2.0  3.234330e-29  1.617165e-29  3.234330e-29  1.000000\n",
      "Residual             6.0  3.000000e+00  5.000000e-01           NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Software': ['A', 'A', 'B', 'B', 'C', 'C', 'A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Experience': ['Novice', 'Experienced'] * 6,\n",
    "    'Time': [10, 12, 14, 16, 20, 22, 11, 13, 15, 17, 19, 21]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ Software + Experience + Software:Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa8d24-9f54-4fc2-9886-376336760627",
   "metadata": {},
   "source": [
    "# Question.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b00be-a036-46e3-bf5d-411ee2a13d09",
   "metadata": {},
   "source": [
    "## An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929f0725-f27d-4cf4-81a9-11aa34c70dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -0.9778766189127441\n",
      "p-value: 0.33049511614004234\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Test scores for control group and experimental group\n",
    "control_group = [78, 82, 75, 88, 92, 79, 81, 85, 90, 86, 80, 83, 87, 84, 77, 91, 89, 76, 82, 85,\n",
    "                 80, 88, 81, 84, 79, 83, 86, 90, 77, 75, 89, 82, 86, 80, 78, 83, 87, 91, 88, 85,\n",
    "                 80, 82, 79, 84, 90, 83, 77, 86, 81, 88, 89]\n",
    "\n",
    "experimental_group = [85, 89, 92, 78, 83, 90, 88, 81, 86, 84, 82, 79, 88, 83, 90, 87, 84, 79, 82,\n",
    "                      85, 81, 77, 89, 86, 83, 90, 88, 82, 79, 85, 87, 80, 83, 88, 81, 90, 84, 82,\n",
    "                      79, 86, 83, 89, 88, 77, 81, 85, 83, 90, 84, 82, 86]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (e.g., Tukey's HSD)\n",
    "if p_value < 0.05:\n",
    "    # Additional code for post-hoc test\n",
    "    # Perform post-hoc test using appropriate method\n",
    "    # Print post-hoc test results\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7087c34-fdd5-4c76-a517-0ccbfae5aaca",
   "metadata": {},
   "source": [
    "# Question.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bb864-99cc-4368-8bbd-ac225fab233d",
   "metadata": {},
   "source": [
    "## A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc3fb3-54d2-41c5-a2a0-973fc6936cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Day': list(range(1, 31)) * 3,\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': [100, 110, 120, 105, 115, 125, ...]  # Sales data for each day and store\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Sales ~ Store + C(Day)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA results\n",
    "print(anova_table)\n",
    "\n",
    "# Perform post-hoc test (e.g., Tukey's HSD)\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'])\n",
    "    print(posthoc.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
