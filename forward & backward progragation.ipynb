{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02148824-f39a-4396-9bfd-f18039e14d56",
   "metadata": {},
   "source": [
    "# Question.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750e277-fdb7-4def-98ca-54d38412db0e",
   "metadata": {},
   "source": [
    "## What is the purpose of forward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431dee3e-a935-4b38-a315-fbc3cfdf373b",
   "metadata": {},
   "source": [
    "Forward propagation is a fundamental process in a neural network that involves passing input data through the network's layers to generate an output prediction. It serves the purpose of transforming input data through a series of weighted computations and activation functions to produce a meaningful output or prediction.\n",
    "\n",
    "The primary objectives of forward propagation are as follows:\n",
    "\n",
    "1. **Prediction Generation:** Forward propagation calculates the network's output or prediction based on the given input data. This prediction can be used for various tasks such as classification, regression, and more.\n",
    "\n",
    "2. **Feature Transformation:** As the input data passes through each layer of the network, it undergoes transformations due to the weights, biases, and activation functions. This transformation enables the network to learn complex patterns and relationships in the data.\n",
    "\n",
    "3. **Information Processing:** Forward propagation involves computing weighted sums of inputs, applying activation functions, and passing the resulting values to the next layer. This process allows the network to capture and process information from the input data.\n",
    "\n",
    "4. **Decision-Making:** The final output of the forward propagation process is used to make decisions or predictions based on the learned information. For example, in image classification, the output might represent the predicted class of the input image.\n",
    "\n",
    "5. **Training and Loss Calculation:** During training, forward propagation is essential to calculate the predicted outputs and compare them to the actual labels to compute the loss. This loss is then used to update the network's weights and biases through backpropagation to improve its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54e554-b3f6-4d34-aed7-1aca9c55b8a1",
   "metadata": {},
   "source": [
    "# Question.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ec09d-3669-4036-857f-3833cf7d96f0",
   "metadata": {},
   "source": [
    "## How is forward propagation implemented mathematically in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994f6d8-8834-4f52-b631-3aa15c815f68",
   "metadata": {},
   "source": [
    "In a single-layer feedforward neural network, also known as a perceptron, there is only one layer of neurons that directly connects to the output layer. The process of forward propagation in such a network involves computing the weighted sum of input features, applying an activation function, and generating the final output. Here's how forward propagation is implemented mathematically in a single-layer feedforward neural network:\n",
    "\n",
    "Let's consider the following notation:\n",
    "- \\( x = [x_1, x_2, \\ldots, x_n] \\) is the input feature vector of length \\( n \\).\n",
    "- \\( w = [w_1, w_2, \\ldots, w_n] \\) are the weights corresponding to the input features.\n",
    "- \\( b \\) is the bias term.\n",
    "- \\( z \\) is the weighted sum of inputs plus the bias.\n",
    "- \\( a \\) is the output of the activation function.\n",
    "\n",
    "The steps for forward propagation in a single-layer feedforward neural network are as follows:\n",
    "\n",
    "1. **Weighted Sum Calculation:**\n",
    "   Compute the weighted sum of inputs plus the bias:\n",
    "   \\[ z = \\sum_{i=1}^{n} (w_i \\cdot x_i) + b \\]\n",
    "\n",
    "2. **Activation Function:**\n",
    "   Apply an activation function \\( f \\) to the weighted sum \\( z \\) to obtain the output \\( a \\):\n",
    "   \\[ a = f(z) \\]\n",
    "\n",
    "The choice of activation function \\( f \\) depends on the specific problem and network design. Common activation functions used in this context include the sigmoid function (\\( \\sigma \\)), hyperbolic tangent (\\( \\text{tanh} \\)), and rectified linear unit (ReLU).\n",
    "\n",
    "The output \\( a \\) represents the prediction or output of the single-layer feedforward neural network. This process of computing the weighted sum, applying the activation function, and generating the final output constitutes forward propagation.\n",
    "\n",
    "In mathematical notation, the overall forward propagation process can be summarized as:\n",
    "\\[ a = f\\left(\\sum_{i=1}^{n} (w_i \\cdot x_i) + b\\right) \\]\n",
    "\n",
    "Forward propagation is not as complex in single-layer networks compared to more complex architectures, but it serves as the foundation for understanding the flow of information through neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27237b9c-b1c0-4dd3-a147-0d213653d15d",
   "metadata": {},
   "source": [
    "# Question.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e890f863-be00-4ae6-808e-f9df7fdb4332",
   "metadata": {},
   "source": [
    "## How are activation functions used during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadb92f-9797-4c70-b5bd-d07c39c710f9",
   "metadata": {},
   "source": [
    "Activation functions play a crucial role during forward propagation in neural networks. They introduce non-linearity to the network's computations, enabling it to model complex relationships in data and capture patterns that linear transformations alone cannot represent. Activation functions are applied to the outputs of neurons in each layer, transforming the weighted sum of inputs into meaningful outputs. Here's how activation functions are used during forward propagation:\n",
    "\n",
    "1. **Weighted Sum Calculation:**\n",
    "   For each neuron in a layer, the weighted sum of inputs (including biases) is calculated. This is done by multiplying each input value by its corresponding weight, summing up these weighted inputs, and then adding the bias term. Mathematically, this can be represented as:\n",
    "   \n",
    "   \\[ z = \\sum_{i=1}^{n} (w_i \\cdot x_i) + b \\]\n",
    "   \n",
    "   Here, \\( z \\) is the weighted sum, \\( n \\) is the number of inputs, \\( w_i \\) are the weights, \\( x_i \\) are the input values, and \\( b \\) is the bias term.\n",
    "\n",
    "2. **Applying the Activation Function:**\n",
    "   After calculating the weighted sum \\( z \\), the next step is to apply the chosen activation function \\( f \\) to the weighted sum to obtain the output \\( a \\) of the neuron. Mathematically, this can be represented as:\n",
    "   \n",
    "   \\[ a = f(z) \\]\n",
    "   \n",
    "   The activation function \\( f \\) introduces non-linearity to the network. It maps the raw input \\( z \\) to a meaningful output \\( a \\) that captures the neuron's activation level.\n",
    "\n",
    "3. **Propagation to the Next Layer:**\n",
    "   The output \\( a \\) of the neuron becomes the input for the neurons in the next layer. This process of calculating the weighted sum, applying the activation function, and passing the output to the next layer is repeated for each neuron in the network, layer by layer, until the final output layer is reached.\n",
    "\n",
    "Common activation functions include sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), and softmax. Each activation function has its own characteristics, advantages, and limitations, which affect how information is processed and propagated through the network during forward propagation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fd1d1-8ba1-48b0-875d-80e58d00b0d2",
   "metadata": {},
   "source": [
    "# Question.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c4da2-753e-4ae4-bdf8-62855ef830d9",
   "metadata": {},
   "source": [
    "## What is the role of weights and biases in forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963be02-6787-4f95-a7ee-43a841577a99",
   "metadata": {},
   "source": [
    "Weights and biases are fundamental parameters in a neural network that play a crucial role during forward propagation. They determine how input data is transformed and processed as it flows through the network's layers. Let's understand the roles of weights and biases in the context of forward propagation:\n",
    "\n",
    "1. **Weights:**\n",
    "   Weights are numerical values associated with the connections between neurons in different layers of the network. Each input feature is multiplied by its corresponding weight before being summed to calculate the weighted sum. The weights control the strength and direction of the connections between neurons and determine how much influence each input feature has on the neuron's output.\n",
    "\n",
    "   Mathematically, for a neuron with \\( n \\) input features, the weighted sum \\( z \\) is calculated as:\n",
    "   \n",
    "   \\[ z = \\sum_{i=1}^{n} (w_i \\cdot x_i) \\]\n",
    "   \n",
    "   Here, \\( w_i \\) represents the weight associated with the \\( i \\)th input feature, and \\( x_i \\) represents the \\( i \\)th input value.\n",
    "\n",
    "2. **Biases:**\n",
    "   Biases are additional parameters associated with each neuron in a layer, independent of the input features. They provide an offset to the weighted sum, allowing the neuron to activate even when all input values are zero. Biases help control the baseline activation level of neurons and shift the activation function along the input axis.\n",
    "\n",
    "   The weighted sum \\( z \\) is then modified to include the bias term \\( b \\):\n",
    "   \n",
    "   \\[ z = \\sum_{i=1}^{n} (w_i \\cdot x_i) + b \\]\n",
    "\n",
    "   The bias term \\( b \\) can have a significant impact on the activation level of the neuron, even in the absence of strong input signals.\n",
    "\n",
    "3. **Transformation and Output:**\n",
    "   The weighted sum \\( z \\) obtained after multiplying input features by weights and adding the bias is then passed through an activation function. This introduces non-linearity and transforms the weighted sum into an output \\( a \\), which is the activation of the neuron. The output \\( a \\) is then used as the input for neurons in the next layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904afaf-1e9c-4775-a1df-926a2a99c2df",
   "metadata": {},
   "source": [
    "# Question.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a4f06-c0cd-4362-bb77-377d38d2add6",
   "metadata": {},
   "source": [
    "## What is the purpose of applying a softmax function in the output layer during forward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8410a0-de46-4b6a-9ebe-79b507683582",
   "metadata": {},
   "source": [
    "The purpose of applying a softmax function in the output layer during forward propagation is to transform the raw scores (logits) produced by the previous layers into a probability distribution over multiple classes. This probability distribution indicates the likelihood of the input belonging to each class. The class with the highest probability is predicted as the final output class.\n",
    "\n",
    "In multi-class classification tasks, the softmax function helps the neural network provide a meaningful and interpretable prediction by converting raw scores into probabilities. Here's how the softmax function serves its purpose during forward propagation:\n",
    "\n",
    "1. **Raw Score Calculation:**\n",
    "   In the output layer, each neuron produces a raw score (logit) that represents the network's confidence or evidence for each class. These raw scores are often the result of weighted sum computations and activation functions applied in earlier layers.\n",
    "\n",
    "2. **Normalization and Probability Calculation:**\n",
    "   The softmax function takes these raw scores as input and normalizes them to ensure that they are positive and sum up to 1, forming a valid probability distribution. It does this by exponentiating each raw score and dividing by the sum of exponentiated raw scores. Mathematically, for class \\( i \\), the softmax function is defined as:\n",
    "   \n",
    "   \\[ \\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{k} e^{z_j}} \\]\n",
    "   \n",
    "   Here, \\( z_i \\) is the raw score for class \\( i \\), \\( k \\) is the number of classes, and \\( e \\) is the base of the natural logarithm.\n",
    "\n",
    "3. **Interpretable Probabilities:**\n",
    "   The resulting normalized values from the softmax function represent the probabilities of the input belonging to each class. These probabilities sum up to 1, making them interpretable as likelihoods. The class with the highest probability is the predicted class.\n",
    "\n",
    "4. **Choosing the Most Likely Class:**\n",
    "   After applying the softmax function, the class with the highest probability is selected as the predicted class for the input. This process allows the network to make a final decision about the input's classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f0df2-44af-4254-9473-108c7b2ab113",
   "metadata": {},
   "source": [
    "# Question.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a4cf6-a68e-4fbb-b87a-dafd908a2ef2",
   "metadata": {},
   "source": [
    "## What is the purpose of backward propagation in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd552a0-a9e5-44ff-a5c6-a5a169501639",
   "metadata": {},
   "source": [
    "Backward propagation, also known as backpropagation, is a fundamental process in training a neural network. Its purpose is to calculate the gradients of the network's loss with respect to its weights and biases, enabling the network to learn and adjust its parameters through gradient-based optimization algorithms. In other words, backward propagation is responsible for updating the network's parameters to minimize the difference between its predictions and the actual target values.\n",
    "\n",
    "The main objectives of backward propagation are as follows:\n",
    "\n",
    "1. **Gradient Calculation:** During forward propagation, the network produces predictions based on the current weights and biases. Backward propagation calculates the gradients of the loss function with respect to these weights and biases. These gradients indicate the direction and magnitude of changes required in each parameter to reduce the loss.\n",
    "\n",
    "2. **Error Backpropagation:** Backward propagation propagates the error from the output layer back through the network to compute the gradients at each layer. It computes how much each parameter contributed to the error and adjusts the parameters accordingly.\n",
    "\n",
    "3. **Parameter Update:** The computed gradients are used to update the network's parameters using gradient-based optimization algorithms such as stochastic gradient descent (SGD), Adam, RMSProp, etc. These algorithms adjust the parameters in the direction that reduces the loss function.\n",
    "\n",
    "4. **Learning and Adaptation:** By iteratively adjusting the parameters using the gradients calculated through backward propagation, the network learns to make better predictions and adapt to the underlying patterns in the training data.\n",
    "\n",
    "The steps involved in backward propagation include:\n",
    "\n",
    "1. **Compute Output Error:** Calculate the error or loss between the network's predictions and the actual target values.\n",
    "\n",
    "2. **Compute Gradients:** Starting from the output layer, compute the gradients of the loss with respect to the output of each neuron. Then, use the chain rule to calculate the gradients with respect to the weights and biases at each layer.\n",
    "\n",
    "3. **Backpropagate Error:** Propagate the gradients backward through the network, layer by layer, using the chain rule. Compute the gradients at each layer and update the weights and biases accordingly.\n",
    "\n",
    "4. **Update Parameters:** Use the computed gradients to update the parameters (weights and biases) using the chosen optimization algorithm.\n",
    "\n",
    "5. **Iterate and Learn:** Repeat the process for multiple epochs or iterations to gradually improve the network's performance by minimizing the loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdffcb-178e-4fcb-ac0a-b0590efede1c",
   "metadata": {},
   "source": [
    "# Question.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d76fb-4d46-49f1-93a1-6bcf7ad831a7",
   "metadata": {},
   "source": [
    "## How is backward propagation mathematically calculated in a single-layer feedforward neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f3353-bb55-40d8-b5a1-aa4d94c09841",
   "metadata": {},
   "source": [
    "In a single-layer feedforward neural network, backward propagation involves calculating gradients with respect to the weights and biases of the network's only layer. Here's how backward propagation is mathematically calculated in a single-layer feedforward neural network:\n",
    "\n",
    "Let's consider the following notation:\n",
    "- \\( x = [x_1, x_2, \\ldots, x_n] \\) is the input feature vector of length \\( n \\).\n",
    "- \\( w = [w_1, w_2, \\ldots, w_n] \\) are the weights corresponding to the input features.\n",
    "- \\( b \\) is the bias term.\n",
    "- \\( z \\) is the weighted sum of inputs plus the bias.\n",
    "- \\( a \\) is the output of the activation function.\n",
    "- \\( y \\) is the target or actual output value.\n",
    "- \\( L \\) is the loss function.\n",
    "\n",
    "The steps for backward propagation in a single-layer feedforward neural network are as follows:\n",
    "\n",
    "1. **Calculate Output Error:**\n",
    "   Calculate the error between the predicted output (\\( a \\)) and the target output (\\( y \\)):\n",
    "   \\[ \\delta = a - y \\]\n",
    "\n",
    "2. **Calculate Weight Gradient:**\n",
    "   Calculate the gradient of the loss function (\\( L \\)) with respect to the weights (\\( w \\)):\n",
    "   \\[ \\frac{\\partial L}{\\partial w_i} = \\delta \\cdot x_i \\]\n",
    "   \n",
    "   This represents how the loss changes with respect to a small change in the \\( i \\)th weight.\n",
    "\n",
    "3. **Calculate Bias Gradient:**\n",
    "   Calculate the gradient of the loss function (\\( L \\)) with respect to the bias (\\( b \\)):\n",
    "   \\[ \\frac{\\partial L}{\\partial b} = \\delta \\]\n",
    "   \n",
    "   This represents how the loss changes with respect to a small change in the bias.\n",
    "\n",
    "4. **Update Weights and Biases:**\n",
    "   Use the computed gradients to update the weights and bias using an optimization algorithm, such as stochastic gradient descent (SGD).\n",
    "\n",
    "The gradients calculated in steps 2 and 3 indicate the direction and magnitude of changes needed in the weights and bias to reduce the loss. The network's parameters are then updated using these gradients to improve its performance over subsequent iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c45f46-459a-40a5-89a6-762741f4fda2",
   "metadata": {},
   "source": [
    "# Question.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6a3a1-0f5d-4a07-b094-b65475ad94b5",
   "metadata": {},
   "source": [
    "## Can you explain the concept of the chain rule and its application in backward propagation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48b1f5-8826-4fad-bbef-bf51f14bac69",
   "metadata": {},
   "source": [
    "The chain rule is a fundamental concept in calculus that allows you to compute the derivative of a composite function. In the context of neural networks and machine learning, the chain rule is a crucial tool used during backward propagation to calculate gradients with respect to the parameters of the network. It enables the calculation of gradients at each layer by \"chaining\" together the derivatives of functions within the network.\n",
    "\n",
    "Mathematically, the chain rule states that if you have a composition of functions \\( y = f(g(x)) \\), where \\( f \\) and \\( g \\) are differentiable functions, then the derivative of \\( y \\) with respect to \\( x \\) is given by:\n",
    "\n",
    "\\[ \\frac{dy}{dx} = \\frac{dy}{dg} \\cdot \\frac{dg}{dx} \\]\n",
    "\n",
    "In the context of neural networks, consider a neural network with multiple layers, each containing various computations such as weighted sums, activation functions, and transformations. When calculating gradients during backward propagation, the chain rule allows you to break down the calculation of the gradient at each layer into a sequence of simpler derivatives.\n",
    "\n",
    "Here's how the chain rule is applied in backward propagation:\n",
    "\n",
    "1. **Error Backpropagation:**\n",
    "   During forward propagation, the network computes an output \\( \\hat{y} \\) based on the input features. The difference between \\( \\hat{y} \\) and the actual target \\( y \\) is the error \\( \\delta \\).\n",
    "\n",
    "2. **Gradients Calculation:**\n",
    "   Starting from the output layer and moving backward, the chain rule is applied to compute gradients of the loss function with respect to the parameters (weights and biases) at each layer. At each step, the gradient is calculated by combining the gradients from the subsequent layer and the derivatives of the local computations within the layer.\n",
    "\n",
    "3. **Chaining Derivatives:**\n",
    "   In each layer, the chain rule allows you to break down the computation of the gradient into sequential derivatives. For example, if the output of a layer \\( L \\) is passed through an activation function \\( f \\), then the gradient of the loss with respect to the output of layer \\( L \\) (\\( \\frac{\\partial L}{\\partial \\text{output}_L} \\)) is multiplied with the derivative of the activation function (\\( \\frac{df}{d\\text{output}_L} \\)) to obtain the gradient of the loss with respect to the weighted sum (\\( \\frac{\\partial L}{\\partial \\text{weighted sum}_L} \\)).\n",
    "\n",
    "4. **Recursive Calculation:**\n",
    "   The chain rule is applied recursively from the output layer to the input layer. Each layer's gradient is calculated based on the gradient from the subsequent layer and the derivatives of the local computations in that layer.\n",
    "\n",
    "By leveraging the chain rule, gradients can be efficiently calculated through the network, enabling the adjustment of parameters through optimization algorithms during training. This process allows the network to learn and adapt its parameters to minimize the loss and improve its performance on the given task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcebed8-590f-4fa5-b30d-b63c86e589fc",
   "metadata": {},
   "source": [
    "# Question.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265c74e-5654-41a2-8ed5-7c4d8b68d66f",
   "metadata": {},
   "source": [
    "## What are some common challenges or issues that can occur during backward propagation, and how can they be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920089fb-25ef-41ce-a26b-d7fc97875fbe",
   "metadata": {},
   "source": [
    "During backward propagation, several challenges and issues can arise that might impact the training process and the overall convergence of a neural network. Addressing these challenges is crucial for successful training. Some common challenges and their solutions are:\n",
    "\n",
    "1. **Vanishing Gradients:**\n",
    "   When gradients become very small during backpropagation, layers that are far from the output receive weak updates, slowing down learning or causing them to learn less effectively. This can happen with certain activation functions, especially sigmoid and tanh, for deep networks.\n",
    "\n",
    "   **Solution:** Use activation functions like ReLU, Leaky ReLU, and variants that mitigate the vanishing gradient problem. Weight initialization techniques, like He initialization, can also help.\n",
    "\n",
    "2. **Exploding Gradients:**\n",
    "   The opposite of vanishing gradients, exploding gradients occur when gradients become too large, leading to oscillations or divergence in training.\n",
    "\n",
    "   **Solution:** Gradient clipping is a technique where gradients are scaled down if they exceed a certain threshold during training. It helps prevent gradients from becoming too large.\n",
    "\n",
    "3. **Numerical Precision Issues:**\n",
    "   During computation, numerical precision errors can accumulate, leading to small values being truncated and causing instability in gradient calculations.\n",
    "\n",
    "   **Solution:** Using appropriate data types (e.g., 32-bit or 64-bit floating point), and techniques like gradient normalization can help manage numerical precision issues.\n",
    "\n",
    "4. **Incorrect Weight Updates:**\n",
    "   Bugs in the implementation can lead to incorrect weight updates, affecting the convergence of the network.\n",
    "\n",
    "   **Solution:** Carefully review the implementation of backward propagation and gradient calculations to ensure correctness. Debugging and validating with gradient checking can help identify issues.\n",
    "\n",
    "5. **Non-Optimal Activation Functions:**\n",
    "   Choosing inappropriate activation functions can slow down convergence or hinder the network's ability to learn complex patterns.\n",
    "\n",
    "   **Solution:** Experiment with various activation functions to find the ones that work best for the problem. ReLU and its variants are commonly used due to their effectiveness.\n",
    "\n",
    "6. **Inconsistent Learning Rates:**\n",
    "   Inconsistent learning rates across layers can lead to imbalanced updates and hinder convergence.\n",
    "\n",
    "   **Solution:** Use adaptive optimization algorithms like Adam, RMSProp, or use learning rate schedules that adjust the learning rate based on training progress.\n",
    "\n",
    "7. **Network Architecture:**\n",
    "   Poorly chosen network architectures (e.g., too shallow, too deep) can lead to training difficulties and suboptimal performance.\n",
    "\n",
    "   **Solution:** Experiment with different network architectures and layer sizes. Techniques like dropout and batch normalization can also help stabilize training.\n",
    "\n",
    "8. **Data Quality and Preprocessing:**\n",
    "   Poor quality or unnormalized data can introduce noise or make the optimization process challenging.\n",
    "\n",
    "   **Solution:** Ensure data preprocessing includes scaling, normalization, and data augmentation when necessary. Address data quality issues that might adversely affect training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd59158-8073-40ee-a64c-4aabb5d5525c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48919679-7705-4e5f-8405-6a440d27622f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
